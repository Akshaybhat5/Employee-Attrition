# -*- coding: utf-8 -*-
"""Employee_Attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m-hlyze0gXDyJfYVGRU3PL1g8TVj_v8U

**EMPLOYEE ATTRITION**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

data = pd.read_csv('HR.csv')

data.head()

# let's remove employee count, empployee number, over 18, and standard hours

data.drop(['EmployeeCount','EmployeeNumber','Over18','StandardHours'], axis = 1, inplace=True)

data.head()

data['Attrition'] = data['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)

data.head()

data.shape

data.info()

data.describe()

# figure out if there is any outliers

# Age
sns.set_theme(style='darkgrid')
sns.displot(data['Age'])
plt.title('AGE', fontweight = 'bold')
plt.tight_layout()

# DailyRate
sns.displot(data['DailyRate'])
plt.title('DailyRate', fontweight = 'bold')
plt.tight_layout()

# DistanceFromHome	

sns.displot(data['DistanceFromHome'])
plt.title('DistanceFromHome', fontweight = 'bold')
plt.tight_layout()

# YearsAtCompany

sns.displot(data['YearsAtCompany'])
plt.title('YearsAtCompany', fontweight = 'bold')
plt.tight_layout()

# TotalWorkingYears

sns.displot(data['TotalWorkingYears'])
plt.title('TotalWorkingYears', fontweight = 'bold')
plt.tight_layout()

# It seems there is not outliers

# Age v/s Attrition

plt.figure(figsize=(15,10))

# fig
sns.countplot(x = data['Age'], hue = data['Attrition'])
plt.title('AGE AND ATTRITION', fontweight = 'bold')
plt.tight_layout()

# let's calculate the number of employees who left the company
df_left = data[data['Attrition'] == 1]

print(f'The employees who left the company: {len(df_left)}')
print(f'The employees who left the company in %: {round(len(df_left)/ len(data)*100, 2)}%')

# let's calculate the number of employees who stayed in the company

df_stay = data[data['Attrition']==0]

print(f'The number of employees who stayed in the company: {len(df_stay)}')
print(f'The number of employees who stayed in % : {round(len(df_stay) / len(data)*100, 2)}%')

plt.figure(figsize=(20,20))

# jobrole v/s attrition
plt.subplot(411)
sns.countplot(x = data['JobRole'], hue = data['Attrition'])
plt.title('JOB ROLE', fontweight = 'bold')

# Department v/s attrition
plt.subplot(412)
sns.countplot(x = data['Department'], hue = data['Attrition'])
plt.title('DEPARTMENT', fontweight = 'bold')

# BusinessTravel vs attrition
plt.subplot(413)
sns.countplot(x = data['BusinessTravel'], hue = data['Attrition'])
plt.title('BUSINESS TRAVEL', fontweight = 'bold')

plt.tight_layout()

# gender vs monthly income

plt.figure(figsize=(12,8))

sns.boxplot(x = data['MonthlyIncome'], y = data['Gender'])
plt.title('GENDER V/S MONTHLY INCOME', fontweight = 'bold')
plt.tight_layout()

# jobrole vs monthly income

plt.figure(figsize=(16,8))

sns.boxplot(x = data['MonthlyIncome'], y = data['JobRole'])
plt.title('JOB ROLE V/S MONTHLY INCOME', fontweight = 'bold')
plt.tight_layout()

# split the data into x and y 

data.head()

data['OverTime'] = data['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)

# categorical data
X_cat = data[['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus']]

X_cat

# encoding the categorical data

encoder = OneHotEncoder()
X_cat = encoder.fit_transform(X_cat).toarray()

X_cat

# Numerical values

data.columns

# 'BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus'
# Remove all the above columns and attrition

X_num = data[['Age','DailyRate',
       'DistanceFromHome', 'Education',
       'EnvironmentSatisfaction','HourlyRate', 'JobInvolvement',
       'JobLevel','JobSatisfaction',
       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'OverTime',
       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',
       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',
       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
       'YearsSinceLastPromotion', 'YearsWithCurrManager']]

X_cat = pd.DataFrame(X_cat)

X_cat

# concate both categorical and numerical data

X_all = pd.concat([X_cat, X_num], axis = 1)

X_all

# standardize the data

scalar = MinMaxScaler()
X = scalar.fit_transform(X_all)

X

y = data['Attrition']

y

# split the data into training testing and split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

X_train.shape, X_test.shape

# Logistic regression model
log = LogisticRegression()
log.fit(X_train, y_train)

log_out = log.predict(X_test)

print(log_out)

cm = confusion_matrix(y_test, log_out)
ac = accuracy_score(y_test, log_out)
cl = classification_report(y_test, log_out)

print(f'''The confusion metrix is:
{cm}''')
print(f'The accuracy score is: {round(ac, 2)*100}%')
print(f'''The classification report is:
{cl}''')

# Random Forest model

forest = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_split=3)
forest.fit(X_train, y_train)

forest_out = forest.predict(X_test)

print(forest_out)

cm = confusion_matrix(y_test, forest_out)
ac = accuracy_score(y_test, forest_out)
cl = classification_report(y_test, forest_out)

print(f'''The confusion metrix is:
{cm}''')
print(f'The accuracy score is: {round(ac, 2)*100}%')
print(f'''The classification report is:
{cl}''')

# let's use tensorflow model

model = tf.keras.models.Sequential()

# input layer
model.add(tf.keras.layers.Dense(units=500, activation='relu'))

# hidden layers
model.add(tf.keras.layers.Dense(units=500, activation='relu'))
model.add(tf.keras.layers.Dense(units=500, activation='relu'))

# output layer
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

# model compiling
model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])

# model fitting
R = model.fit(X_train, y_train, batch_size=50, epochs=100)

y_pred = model.predict(X_test)

y_pred = (y_pred>0.5)

y_pred

cl = classification_report(y_test, y_pred)

print(cl)

ac = accuracy_score(y_test, y_pred)
print(ac)

# The loss during model training

plt.plot(R.history['loss'], label = 'LOSS DURING MODEL TRAINING')
plt.title('LOSS', fontweight = 'bold')
plt.xlabel('EPOCHS', fontweight = 'bold')
plt.legend()
plt.show()

# The accuracy during model training

plt.plot(R.history['accuracy'], label = 'ACCURACY DURING MODEL TRAINING', color = 'red')
plt.title('ACCURACY', fontweight = 'bold')
plt.xlabel('EPOCHS', fontweight = 'bold')
plt.legend()
plt.show()

model.save('EMPLOYEE_ATTRITION.h5')

